* Auswändig lernen 重要问题 需记忆
* 02_Wahrnehmung und Bildakquise
** Was ist Licht?
Das Licht ist sichtbarer Teil des elektromagnetischen Spektrums, 380-780nm, charakterisiert durch Lichtintensität(physikalische Größe) und Helligkeit(wahrgenommene Größe)
** Lichtwahrnehmung erfolgt in zwei Schritten
1. Reizaufnahme durch Rezeptoren auf der Retina(Netzhaut)
   - Stäbchen:Schwarz-Weiß-Sehen uach bei geringerer Licht-Intensität(120Mi.)
   - Zapfen:Farbwahrnehmung(ca.6.5 Mi.)
2. Verarbeitung der Reize in mehreren Stufen
   - Kontrastverstärkung am Ausgang der Retina
   - Interpretation im visuellen Kortex des Gehirns.
** Das menschliche Auge
- schwarz/weiße Strukturen feiner auflösen als farbige, s/w ist optimiert für die Erkennung von Konturen.
- farbige Flächen besser wahrnehmen als schwarz/weiße, Farbsehen ist optimiert für die Bewertung von Flächen.
** !Lechners Gesetz
- Die Beziehung zwischen der ins Auge einfallenden Lichtintensität und der vom Auge wahrgenommenen Lichtintensität ist nicht linear sondern annähernd logarithmisch.
- Kleine Helligkeitsunterschiede in dunklen Regionen sind besser wahrnehmbar als vom Betrag her identische Unterschiede in hellen Regionen.
** !Mach-Band-Effekt
+ Interaktion der Lichtrezeptoren im Auge betont "scharfe" Intensitätsänderungen.
+ Sobald das Auge bei der einfallenden Intensität solche Änderungen feststellt, addiert es zusätzlich Unterschwinger und Überschwinger zur wahrgenommenen Intensität, die den Übergang zusätzlich betonen.
+ Dieser unbewußte Mechnismus der Kantenbetonung bei Intensitätsübergängen verhilft unserer visuellen Wahrnehmung zu einer automatischen Konturenschärfe.
** Beleuchtung
*** Anordnung von Beleuchtung
Anordnung von Beleuchtung und Kamerasystem in Bezug auf das zu betrachtende Objekt
- Je nach Aufgabenstellung ist es nötig, eine geeignete Anordnung der verwendeten Komponenten Lichtquelle und Kamerasystem zu finden
- Bei der Erstellung einer Lösung in der Technischen Bild verarbeitung ist oftmals die Anordnung der Komponenten entscheidender als die Komponenten selbst.
*** Fall 1: Das zu betrachtende Objekt befindet sich zwischen Lichtquelle und Kamera
- Das Licht wird im Bereich des Objekts "unterbrochen"
- Es wird ein Schatten(Kontur) abgebildet.
- Sehr gut bei Vermessungsaufgaben, da eindeutige Trennung von Objekt und Hintergrund. Die Oberfläche wird nicht abgebildet.
- verwendung :: wenn die Silhouette des Objektes die entscheidende Information trägt.

*** Fall 2:Lichtquelle und Kamera befinden sich in Bezug auf das zu betrachtende Objekt auf der gleichen Seite.
- Das Licht wird von der Oberfläche des Objekts und des Hintergrunds reflektiert.
- Es wird ein Abbild des Objektes in verschiedenen Grautönen erzeugt.
- Die Oberfläche ist zu erkennen, die Kontur wird nicht so klar dargestellt.
- Anwendung :: bei z.B. Oberflächeninspektionen.

*** Fall 3:Die Lichtquelle strahlt das Licht in einer Vorzugsrichtung ab
- Das Objekt wird aus einer Vorzugsrichtung beleuchtet.
- Durch die Oberflächenstruktur(Erhöhung bzw. Vertiefung) des Objekts bilden sich Schatten bzw. hellere Bereiche, die bestimmte Merkmale deutlich hervortreten lassen.
- Unterscheidung ::
  + Hellfeld :: Wird ein Großteil des von der Probe gerictet reflektierten Lichts vom Objektiv eingefangen, so erscheint das Objekt in der Abbildung hell(Hellfeldbeleuchtung)
  + Dunkelfeld :: Erfolgt die Beleuchtung jedoch so weit von der Seite, dass das gerichtet refletierte Licht am Objektiv vorbei strahlt, spricht man von Dunkelfeldbeleuchtung.
- Fall 3a): Das Kamerasystem befindet sich im Strahlengang(Einfallswinkel = Ausfallswinkel) des reflektierten Lichts
- Fall 3b) Dunkelfeld: Das Kamerasystem befindet sich nicht im Strahlengang(Einfallswinkel != Ausfallswinkel) des reflektierten Lichts
  - Verstärkung von Unebenheiten bei Dunkelfeldaufnahmen
  - glatte, Stark reflektierende Flächen erscheinen dunkel.
  - Kanten und Oberflachendefekte wie Kratzer oder Auflagerungen leichten jedoch hell.
*** Anordnung de Probe sipelt ggf. große Rolle

** Wellenlängenabhängige Effekte - farbige Beleuchtung
+ Farbige Objekte reflektieren einen Teil des Lichtspektrums und absorbieren einen anderen Teil
+ Farbige Beleuchtung kann dazu verwendet werden, den Kontrast zwischen den Objekten und dem Hintergrund zu erhöhen.
** Diffuses vs gerichtetes Licht
+ Diffuse Hellfeld-Auflichbeleuchtung
+ Verwendung:Vermeidugn von spiegelnden Reflexionen
** Polarisierte Beleuchtung
+ Licht wird durch Reflexion an metallischen und dielektrischen Oberflächen polarisiert
+ Um die spiegelnden Reflexionen zu unterdrücken, kann eine Kombination aus zwei Polarisationsfiltern verwendet werden
** !Objektive, Blende und Schärfe
+ Ziel: Erzeugung eines scharfen, unverzerrten, kontrastreichen Bildes
+ Objektive werden als eine Linse mit einer Blende betrachtet
+ Ein parallel zur optischen Achse einfallender Strahl verläuft hinter de rLinse durch den Brennpunkt F'
+ Ein Strahl, der durch den vor der Linse liegenden Brennpunkt F einfällt, verläuft hinter der Linse parallel zur optischen Achse.
+ Ein Strahl, der durch den Knotenpunkt N der Linse verläuft, verlässt die Linse durch N' und verändert seine Richtung nicht.
+ Strahlen, die von einem Punkt des Objektes ausgehen, schneiden sich hinter der Linse in einem Punkt
+ Die Entfernung des Objektes zur Mittelebene der Linse nennt man Gegenstandsweite
+ Die Entfernung dieser scharf abgebildeten Punkte zur Mittelebene der Linse nennt man Bildweite
+ Die Entfernung der Brennpunkte F und F' zu den Hauptebenen der Linse nennt man Brennweite f bzw. f'
+ 2 - 28 Gesetz
+ Die Lichtmenge pro Flächeneinheit, die auf den Sensor fällt, hängt von der Belichungsdauer t, von der Größe d der Blendenöffnung un d vom Abstand f' des Sensors von der Linse ab.
+ Schärfentiefe ::
  - Die Bildweite, bei der ein Objekt exakt scharf abgebildet wird, lässt sich aus der Gegenstandsweite und der Brennweite ableiten
  - Entferntere oder nähere Bildpunkte werden auf einen Zerstreuungskreis(blur circle) abgebildet
  - Innerhalb eines gewissen Bereichs der Gegenstandsweite ist der Zerstreuungskreis so klein, dass keine merkliche Unschärfe auftritt
+ Chromatische Aberration ::
  - Beschreibung: Lichtberechung einer ist Linse von der Wellenlänge des Lichts abhängig. Farben des Spektrums haben keinen gemeinsamen Brennpunkt. Es treten Unschärfen im Bild auf.
+ Sphärische Abberation ::
  - Beschreibung:Sphärische Linsen haben im Zentrum und am Rand unterschiedliche Brennweiten
  - Es treten Unschärfen im Bild auf
  - Objektiv-Bauwese im Detail ändern
+ Verzeichung ::
  - Beschreibung: Nichtsymmetrischer Aufbau der Optik mit Blende vor oder hinter dem optischen Zentrum der Optik
+ Telezentrische Objektive
  - Telezentische Objektive bieten eine Parallelprojektion des Objektes
  - Bildgröße ist unabhängig von der Gegenstandsweite
  - Realisierung: Positionierung einer Blende im Brennpunkt
    - Nur parallele Strahlen können die Blende passieren
    - Durchmesser des Objektivs muss größer sein als das aufzunehmende Objekt
* 03_Bildrepräsentation und Punktoperationen
** Digitalisierung von Bildern
+ Natürliche Bilder sind stetig, d.h: es gibt unendlich viele "Bildpubkt",und unendlich viele Grauwerte.
+ Bilder müssen digitalisiert werden, um die Datenmengen zu begrenzen und ein Speichern/Verarbeiten im Rechner zu ermöglichen.
+ Digitalisierung =
  - 1. Diskretisierung(stetig -> endliche Anzahl von Zuständen)
  - 2. Codeirung (Bezeichnung der Zustände)

** Was ist ein digitales (Grauwert)Bild?
+ Intensität wird nur an diskreten Punkten der Bildvorlage bzw. des Sensorfeldes gemessen
+ Bildbetrachtung :: Pixelgröße kleiner als räumliche Auflösung des visuellen Systems des beobachters bei gegebener Entfernung.
** Sampling
+ Ziel: Möglichst wenig Speicherplatz pro Bild
+ Sampling :: Abtastung an so wenig Stellen wie möglich bei Erhaltung aller Details.
+ Grudsätzliche Idee:
  - Mathematische Modellierung des Bildes mittels Reihenentwicklung periodischer Funktionen im Frequenzraum
  - Addition verschiedener Frequenzen um originales Signal abzubilden
  - Sampling muss kleinste Frequenz erfassen um Bild ohne Artefakte zu erstellen
+ Nyquit-/Shannon-Theorem
  - Für eine Funktionen, die sich als Summe von Sinus-oder Kosinusschwingungen unterschiedlcher Amplitude udn Frequenz darstellen lässt gilt allgemein: Eine Funktion muss so abgestastet werden, dass das Abtastintervall x kleiner ist, als die Hälfte der kürzesten Wellenlänge r min, um ohne Informationsverlust rekonstruiert werden zu können
** Quantisierung
+ Intensitätsbereich in endlich viele Intervalle zerlegen.
+ zu wenige Grauwerte -> falsche Kanten
+ Konflikt:bildqualität <-> Speicherbedarf/Rechenzeit
** Digitale Topologie: Quadratisches Gitter
+ 4 - bzw. 8-Nachbarschaft eines Bildpunktes p = (r,c)
+ vier direkte Nachbarn:gemeinsame Kante mit p
+ vier in direkte Nachbarn:gemeinsame Ecke
** Bildsensor: Modellvorstellung
Aufbau und Funktionsweise des Bildsensors einer Digitalkamera
+ Oberfläche bedeckt von lichtempfindlichen Zellen, denen jeweils ein Farbfilter vorgeschaltet ist, der nur Licht bestimmter Wellenlänge durchlässt(z.B Rot, Grün oder Blau)
+ jede Zelle ist mit einem Zähler ausgestattet, der während der Belichtungszeit proportional zur einfallenden Lichintensitaät hochzählt. Bereich[0,255]
+ nach der Belichtung weisen Zellen, die kaum Licht empfinden, einen kleinen Wert auf
+ Zellen, die einem starken Lichteinfall ausgesetzt waren, einen hohen Wert.
** Globale Charakterisierung von Bildern - Histogramm
+ Bildgröße MxN, Grauwertbereich [0..255]
+ Absolutes Grauwerthistogramm
  - absolute Häufigkeit, mit welcher Grauwert k auftritt
+ Relatives Grauwerthistogramm
  - Relative Häufigkeit, mit welcher Grauwert k auftritt
  - Interpretation als Wahrscheinlichkeit des Ereignisses Grauwert = k
+ Mittlere Helligkeit
  - Auskunft über allgemeine Helligkeit
+ Varianz und mittlere quadratische Abweichung
  - Varianz ist Maß für Abweichungen der Grauwerte aller Pixel vom Mittelwert f und beschreibt den Kontrast
+ Kumulatives histogramm H(i)
** Eigenschaften und Nutzen von Histogrammen
+ Völlig unterschiedliche Bilder können identische Histogramme haben
  - Aus dem Histogramm sind keine Rückschlüsse auf den Bildinhalt möglich, da der Ortsbezug der Grauwerte fehlt
+ Histogramm zeigt: Belichtung, Kontrast, Dynamik, Bildfehler
+ Das Histogramm eines Bildes kann Informationen über Über-bzw. Unterbelichtung geben(mittig, rechtslastig, linkslastig)
+ Rekonstruktion von Über- oder Unterbelichtung nicht komplett möglich
+ Kontrast
  - genutzter Intensitätsbereich im Bild, d.h. K=(gmax-gmin)/(gmax+gmin),wobei gmin und gmax der Minimale bzw.maximale Grauwert im Bild ist.
+ Dynamik:Anzahl verschiedener Intensitätswerte im Bild
  - Die maximale Dynamik wird dann erreicht, wenn alle zwischen Imin und Imax liegenden Grauwerte im Bild vorkommen
  - Dynamik kann nicht nachträglcih erhöht werden
  - Effekt von Quantisieurng im Histrogramm
+ Nutzen ziehen aus Über-bzw. Unterbelichtung
  - Wenn Szenarien sehr unterschiedlich hell sind, kann eine korrekte Belichtung die alle Details wieder gibt schwierig sein
  - Kombiniere mehrere Aufnahmen
  - Helle Bereiche gut auflösen durch kurze Belichtung
  - Dunkel Bereiche gut auflösen durch lange Belichtung
** Histogramme für Bidler mit mehr als 8 Bit
+ Binning
  - Zählung der Intensitätswerte in B intervallen [aj,a+1]
  - Bei gleichgrossen Bins ergibt sich eine Intervallgröße K = K/B mit aj=j kB.
** Histogramme für Farb-Bilder
 + 1. Möglichkeit: Histogramm pro Farbkanal angeben
 + 2. Möglichkeit: Farbbild in Graubild gleicher Helligkeiten überführen
   - Dabei müssen r,g,b unterschiedlich gewichtet werden
   - I = 0.299 * R + 0.587*G + 0.114*B
 + Ergebnis ist ein Wert, der unabhängig von den Farben die Helligkeit des Bildpunktes wiedergibt
 + Die prozentuale Verteilung der Farben hängt mit der entsprechenden Farbempfindlichkeit der Augen zusammen
** !Punktoperationen
+ Punktoperation f :: jeder neue Pixelwert hängt ausschließlich vom alten Pixelwert ab, unabhängig von anderen Pixelwerten im Bild
  + Beispiel: Grauverlaufsfilter
+ Homogene Punktoperation :: f ist unabhängig von den Bildkkordinaten
  - Beipiele: Änderung von Kontrast und Helligkeit, Anwendung beliebiger Helligkeitskurven, Invertieren und Addieren von Bildern, Schwellwertbildung, Gammakorrektur
+ Punktoperationen:
  + Kontraständerung: fc(a)=1.5 * a
  + Helligkeitsänderung:fi(a)=a+10
  + Beschränkung(clamping):if(a>255) a=255;bzw. if(a<0) a=0;
  + Invertieren:f(a)=amax-a
  + Schwellwert:fth(a)=a0 für a<ath fth(a)=a1 für a>=ath
** Automatische Kontrastanpassung
+ Einfache Kontrastanpassung: Dehne und verschiebe Histogramm:
  - dass dunkelster Pixel alow auf amin,
  - hellster Pixel ahigh auf Maximalwert amax fällt
+ Problem:Einzelne Ausreißer können gesamtes Bild beeinflussen.
+ Robuste Kontrastanpassung mit Quantilen
  + Sei Slow, Shigh der Anteil der Pixel, der in Dunkel-bzw. Hellsättigung übergehen darf, A ist die Fläche des Bildes in Pixeln.(p 3-30)
** Linearer Histogrammausgleich
+ Ziel :: Bild durch homogene Punktoperation so verändern, dass es ein gleichverteiltes Histogramm aufweist.
+ Gleichverteilte Grauwerte haben theoretisch den höchsten Informationsgehalt
+ Homogene Punkoperationen können Histogrammeinträge nur verschieben oder zusammenfügen, nicht aber trennen
+ Die histogrammeinträge werden so verschoben, daß sich näherungsweise ein keilförmiges Histogramm ergibt
+ Bilder sehen unnatürlich aus, da die meisten natürlichen Bilder eher gaußverteilte Histogramme haben
+ Sinn von Histogrammausgleich
  + Serie von Bildern, die etwa bei unterschiedlichen Aufnahmeverhältnissen oder mit verschiedenen Kameras entstanden sind, aber letztlich in der Reproduktion ähnlich aussehen sollen.
  + Notwendig:Anpassung an eine beliebige Verteilung,etwa eine die durch ein Referenzbild gegeben ist
** Anpassung des Histogramms an eine Referenzverteilung
+ Ziel :: Modifiziere Ausgangsbild IA durch homogene Punktoperation so, dass seine Verteilungsfunktion PA möglichst gut mitPr eines Referenzbildes Ir übereinstimmt.
+ Schritt 1: Histogramm wird durch linearen Histogrammausgleich in eine Gleichverteilung überführt
+ Schritt 2: Das Resultat wird über die Inverse Pr(a)-1 der Referenzverteilung transformiert.
** Histogrammausgleich - Stückweise lineare Referenzverteilung
Zwischen N vorgegebenen Stützstellen (ij,qj) wird linear interpoliert
** Histogrammausgleich - Anpassung an Referenzverteilung
+ Problem: Natürliche Verteilungsfunktionen sind oft nicht invertierbar
+ Lösung: Schrittweises "Ausfüllen" der Referenzverteilung
  + D.h.: für einen gegebenen Pixelwert a wird der minimale Wert a0 in Pr(a0) gesucht, bei dem PA(a)< PR(a0) ist.
** Ausgleich oder Kontrast-Anpassung für Farb-Bilder
+ Problem: getrennter Histogrammausgleich oder Kontrast-Anpassung für die 3 Farb-Kanäle würde die relative Zusammensetzung der Farben im finalen Bild ändern.
+ Lösung: Konvertierung von rgb in ein Farb-Modell, bei dem Helligkeits- und Farbinformation getrennt gespreichert werden.
  - Gesucht:Ein passendes Farb-Modell
+ Prozedere:
  1. Konvertiere von rgb nach passendem Modell
  2. Histogrammausgleich/Kontrastanpassung nur für die Helligkeiten durchführen
  3. Rück-Konvertierung ins rgb Modell

+ Das YIQ- bzw. YUV Farbmodell iwrd in der Fernseh-/Videotechnik verwendet
  - Luminanz-Signal(Helligkeit)
  - Chrominanz Signale U und V (PAL)
  - Chrominanz Signale I und Q (NTSC)
** Gamma-Korrektur
+ Reale Aufnahmesysteme(Kameras, Scanner,..) setzen Intensitäten nicht 1:1 in Grauwerte um
  - Die Abbildung von Intensitäten I in Grauwerte ist meist eine nichtlineare Funktion a = F(I)
+ Ebenso setzen Ausgabegeräte(z.B Bildschirme) Grauwerte nicht 1:1 in Helligkeiten um
  - Auch hier gibts Nichtlineartität.

+ Grundidee der Gammakorrektur :: Bilder werden durch eine homogene Punktoperation so transfomiert, dass die geräteabhängige Nichtlinearität kompensiert wird.
+ Nach der Korrektur entprechen die Grauwerte nicht den absoluten Intensitäten, aber ihr relatives Verhältnis ist (idealerweise) gleich wie in der Wirklichkeit.
* 04_LineareFilter
** Filterung - Idee
+ Filtermerkmale
  - Ergebnis wird nicht aus einem einzigen Pixel brechnet, sondern aus einer Menge von Pixeln.
  - Die Koordinaten der Quellpixel habe eine feste relative Position zum Zielpixel und bilden i.A. eine zusammenhängende Region
+ Parameter
  - Größe der Filterregion
  - Form der Filterregion
  - Gewichtung der Quellpixel(konstant oder ortsabhängig)
** Lineare Filter
+ Lineare Filter:Wert des zielpixels wird als gewichtete Summe der Quellpixel berechnet
+ Größe und Form der Filterregion und Gewichte des Filter werden durch eine Matrix von Filterkoeffizienten spezifiziert, der Filtermatrix Hij oder Filtermaske.
+ Die Filtermatrix ist eine diskrete zweidimensionale Funtkion
+ Koordinaten werden meist relativ zum Zentrum angegeben
+ im Gegensatz zu punktoperationen ist bei Filtern keine "in place"-Verarbeitung möglich, da die Quellpixel mehrere Male benötigt werden
+ Zwei prinzipielle Varianten möglich:
  - Ergebnis in ein Zwischenbild speichern, am Schluss komplettes Bild zurückschreiben
  - Alternativ:erst Kopie erstellen und Ergebnisse direkt ins Original-Bild schreiben
+ Implementierungsfragen
  - Oft ist es vorteilhafter, mit ganzzahligen Filterkoeffizienten zu arbeiten
  - Umwandlung und Speicherung des Bildes in Gleitkommaformat nicth sinnvoll
  - Realisierung über einen Skalierungsfaktor,nur eine double-Operation pro pixel
  - Filtergröße kann sehr leicht generisch implementiert werden, typisch: ungeradzahlige Größe, zentriert.
+ Anwendung linearer Filter: Randbehandlung
  1. nur Zentralbereich auswerten, bei dem die Filtermaske ganz ins Bild passt, Outputbild wird kleiner.
  2. Zero padding: Inputbild wird um 0 oder Grauwert erweitert, In-und Outputbild gleich groß. Schwarz oder Grau führt bei Mittelwertbildung zu Artefakten am Rand, insbesondere in hellen Region
  3. Konstante Randbedingung: Die Pixel außerhalb nehmen den Wert des jeweils nächstliegenden Randpixels an. Wenig Artefakte, einfach zu implementieren, haüfig verwendet.
  4. Gespiegelte Randbedingung:Die Pixelwerte werden an der nächstliegenden Bildkante gespiegelt.
  5. Zyklische Randbehandlung: Die pixelwerte wiederholen sich zyklisch in allen Richtungen
  6. Fazit:
     - Wahl der Rand-Methode abhängig vom verwendeten Filter
     - Debugging ob ein Filter korrekt arbeitet schwierig, da nicht notwendigerweise ein Programmabsturz vorliegen muss
     - Analyse der Funktionalität ein einfachen Muster-Beispielen notwendig
** Lineare Filter - Formale Eigenschaften
+ Ziel :: Effiziente Implementierung und Einsparen von Rechenoperationen
+ Vorgehensweise/Methode :: Mathematische Analyse der Filteroperation
Die Faltung f*g zweier Funktionen ist eine mathematische Operation, die der Multiplikation ähnlich ist. Definition: 4-13.
+ Eigenschaften der Faltung
  + Kmmutativität
  + Linearität
  + Assoziativität
+ Aus der Assoziativität ergibt sich, dass ein großer Filter H in mehrere kleine Filter Hi zerlegt werden kann, insbesonderer bei 2 eindimensionalen Filtern in x- und y-Richrung (x/y-Separabilität)
+ Zweidimensionale Filter sind separabel, wenn sie als äußeres Produkt geschrieben werden können:Hxy(i;j)=Hx(i)Hy(j),Beispiel:Gauss-Filter. Bei großen Filtern, da die Anzahl der Schreib-/Lese-Zugriffe und Multiplikationen quadratisch mit der Größe wächst
+ Weitere Eigenschaften der Faltung
  - Die Impuls- oder Dirac-Funktion ist das neutrale Element der Faltung
+ Nutzen der Impulsfunktion
  - Faltung mit der Impulsfunktion ergibt das ursprüngliche Bild
  - Nützlicher:Die Impulsfunktion als Input eines linearen Filters liefert die Filterfunktion H als Ergebnis, d.h. ein unbekannter lin. Filter lässt sich durch Anwendung auf ein Bild mit einem weissen und sonst nur schwarzen Pixeln entschlüsseln. Es steht dann die Filtermatrix im Ergebnis-Bild.
+ Lineare Filter - Grenzen
+ Lineare Glättngsfilter reduzieren zwar Rauschen im Bild, aber gleichzeitig werden Kanten oder Linien verbreitert und im Kontrast reduziert. Lineare Filter bilden immer auf irgend eine Art und Weise Mittelwerte, daher ist die Funktionalität letztlich begrenzt.
** Nicht-Lineare Filter
+ Nichtlieare Filter werden so wie lineare Filter über eine Umgebung R des Zielpixels mit einer nichtlinearen Funktion berechnet, z.B Minimum- und Maximumfilter
+ Minimum- und Maximumfilter auf Salt-Pepper-Rauschen
  - Minimumfilter eliminiert weiße Punkte und verbreitert dunkle Regionen
  - Maximumfilter macht das Gegenteil
+ Median-Filter
  - Der Median-Filter ersetzt jeden Pixel durch den Median seiner Umgebung R
  - bei 2k+1 aufsteigend sortierten Pixeln ist der Median definiert als median{p0,p1,...,pk,...p2k}=pk
  - bei 2k aufsteigend sortierten Pixeln (pk-1 + pk)/2
+ Vergleich :: Linearer Glättungsfilter vs. Medianfilter
  - Der lineare Filter dämpft das Rauschen, macht aber das Bild unscharf
  - Der Medianfilter eliminiert Spitzen/Höhen, erzeugt örtlich Flecken mit konstanter Intensität
+ Erweiterung:gewichteter Median-Filter
 - Grundidee:Wert wird in der sortierten Liste so oft wiederholt, wie sein Gewicht ist. Diese Länge ist die Summe von alle Element in Gewichtmatrix.
* 05_ Kantendetektion
** Movivation
+ Kanten sipelen eine dominante Rolle im menschlichen Sehen:Bildinhalt ist bereits erkennbar, wenn nur wenige Konturen sichtbar sind
+ Subjektiver Schärfeeindruck eines Bildes stht in direktem Zusammenhang mit seiner Kantenstruktur
+ Ein Bild kann beinahe vollständig aus Kanten rekonstruiert werden.
** !Grundlagen
+ Kanten sind Bildorte, an denen sich die Intensität auf kleinem Raum stark verändert.
+ Die Intensitätsänderung bezogen auf die Bilddistanz wird durch die Ableitung der Bildintensität gemessen. In einer Dimension
+ für eine diskrete Funktion ist eine Ableitung nicht definiert
  - Daher: Näheung schätzen
  - Lege eine Gerade durch benachbarte Punkte und berechne die Steigung der Geraden
+ Auch möglich aber in der Bildverarbeitung nicht üblich sind vorwärts-und Rückwärts-Differenz
+ Symmetrische Differenz
+ Partielle Ableitung
  - Ableitung einer mehrdimensionalen Funktion entlang einer der Koordinatenrichtung, d.h. verfolge die Intensitätsänderung entlang einer Zeile oder Spalte.
+ Den Vektor bezeichnet man als Gradient
+ Geometrisch ::
  - Betrachtet man die Bildmatrix als Skalarfeld, so ist der Gradient an einem Punkt ein Vektor, der in Richtung des steilsten des Skalarfeldes weist
  - Der Betrag des Vektors entspricht der Stärke das Anstiegs
+ Der Betrag des Gradienten ist rotationsinvariant
  - d.h. Er ist unabhängig von der Orientierung von Bildstrukturen
  - Diese Eigenschaft ist für die richtungsunabhängige(isotrope) Lokalisierng von Kanten wichtig und daher ist der Betrag auch die Grundlage vieler praktischer Kantendetektoren.
** Ableitungsfilter
+ Realisierung der Symmetrischen Differenz als Filter [-0.5 0 0.5]
+ Anmerkung :: Den Gradienten selbst kann man nict als linearen Filter realisieren, da es sich um ein vektor-wertiges Ergebnis handelt
** Einfache Kantenoperatoren - Prewitt
+ Prewitt-Operator ::
  - verwende Ableitungsfilter, gemittelt über 3 Zeilen bzw. Spalten
  - Mittelung notwendig wegen Rauchanfälligkeit des einfachen Gradientenoperators in x bzw. y Richtung
+ Prewitt-Operator ist separabel
  - Es wird eine (Box-)Glättung gerechnet und dann eine Ableitung geschätzt
  - Aufgrund der Kommutativität der Faltung auch umgekehrt möglich, d.h.,Glättung nach Berechnung der Abteilung
** Einfache Kantenoperatoren - Sobel
+ Sobel-Operator ::
  - Verwende Ableitungsfilter, gemittelt über 3 Zeilen bzw. Spalten mit stärkerer Gewichtung der mittleren Zeile bzw. Spalte.
  - Der Sobel-Operator ist ebenfalls separabel.
** Einfache Kantenoperatoren: Kantenstärke und -Richtng
+ F5-10
** Einfache Kantenoperatoren: Roberts-Operator
+ einer der ältesten und einfachsten Kantenoperatoren, historisch interessant
+ Anmerkung :: Hier wird also eine Rückwärtsdifferenz in Diagonal-Richtung berechnet.
** Kantendetektion mit der zweiten Ableitung
+ Problematisch sind dabei Kanten mit einem langsamen Helligkeitswechsel, die sich damit nicht genau lokalisieren lassen
+ Alternative :: Bestimmung des Nulldurchgangs der zweiten Ableitung.
  - Da die zweite Ableitung noch empfindlicher gegen Rauschen ist, muss das Bild gleichzeitig geglättet werden
** Laplace operator
+ Der Laplace-Operator ist definiert als Summe der zweiten partiellen Ableitung
+ Diskrete Näherung: [1 -2 1]
+ Addiert ergibt sich der Zweidimensionale Laplace Filter
  - Nicht separabel
+ Nulldurchgang markiert genaue Kantenposition
+ Trotz der durch die kleinen Filterkerne ziemlich groben Schätzung der Ableitungen ist das Ergebnis fast perfekt isotrop
+ Summe der Koeffizienten ist null, so dass sich in Bildbereichen mit konstanter Intensität die Filterantwort null ergibt

** !Kanten-Detektion:Canny
+ Ziel ::
  - Gute Detektion:möglichst alle Kanten detektieren, ohne zu viel Clutter
  - Gute Lokalisation: minimale Distanz zwischen detektierter und echter Kante
  - Klare Antwort:nur eine Antwort pro Kante
+ Algoritmus in 3 Arbeitsphasen
  + Vorverarbeitung :: Das Eingangsbild wird mit einem Gaußfilter der Breite σ geglättet, durch das auch die Skalenebene des Kantendetektors spezifiziert wird. Aus dem geglätteten Bild wird für jede Position der x/y-Gradient berechnet sowie dessen Betrag und Richtung.
  + Kantenlokalisierung :: Als Kantenpunkte werden jene Positionen markiert, an denen der Betrag des Gradienten ein lokales Maximum entlang der zugehörigen Gradientenrichtung aufweist.
  + Kantenselektion und -verfolgung :: Im abschließenden Schritt werden unter Verwendung eines Hysterese-Schwellwerts zusammenhängende Ketten von Kantenelementen gebildet.
*** Details für Canny
1. Gerichtet Non-Maximum Suppression der Kantenstärke. Als mögliche Kantenpunkte werden nur jene Elemente betrachetet, an denen das Kantenprofil in der Richtung S0 ein lokales Maximum ist. Die Kantenstärke aaler anderen Elemente wird auf Null gesetzt. (Die Position der Kanten präzise zu bestimmen)
2. Bestimmung der diskreten Kantenrichtung. Trigonometrische Funktionen ist "teuer". Grundsätzlich könnte der zu q gehörige Oktant auch direkt aus den Vorzeichen und Beträgen der Komponenten dx,dy ermittelt werden.
3. Kantenverfolgung mit Hysterese-Schwellwert
   - benachbarte Kantenpunkte, die in der vorherigen Operation als lokale Maximal verblieben sind, zu zusammenhängenden Folgen verketten.
   - Dazu wird eine Schwellwertoperation mit Hyserese verwendet, mit zwei unterschiedlichen Schwellwerten thi,tlo.
   - Das Bild wird nach Elementen mit kantenstärke Enms(u,v)>thi durchsucht
   - Sobald ein solches(bisher nicth besuchtes)Pixel gefunden ist, wird eine neuer Kantenfolge angelegt und alle zusammenhängenden Positionen(u',v') angefügt, solange Enms(u',v')>tlo
   - Dadurch entstehen nur Kantenfolgen, die zumindest ein Element mit einer Kantenstärke größer als thi aufweisen und keien Kantenpunkt mit Kantenstärke unter tlo.
** Kantenschärfung - mit Laplace Filter
+ Kantenschärfung mit dem Laplace-Filter
  - Grundidee :: Überhöhung der Kanten durch Substraktion der zweiten Ableitung lässt das Bild schärfer erscheinen.
  - Achtung :: Schärfung verstärkt auch das Bildrauschen
** Kantenschärfung:Unscharfe Maskierung(unsharp masking -USM)
1. Erzeugung einer gelätteten Version des Bildes
2. Subtraktion der geglätteten Version vom Originalbild: Ergebnis heißt Maske
3. Addition der gewichteten Maske zum Originalbild

+ Oft zusätzlich Mindestwert für den lokalen Bildkontrast, ab dem eine Schärfung vorgenommen wird.
   - Typischerwerise gemessen durch den Betrag des Gradieten, ab dem eine Schärfung an der Stelle (u,v) stattfindet.
+ Laplace-Filter ist Spezialfall des USM-Filters
  
* 06_eckenkurvendetektion
** Algorithmen Idee
ein Eckpunkt ist dort gegeben, wo der Gradient der Bildfunktion gleichzeitig in mehr als einer Richtung einen hohen Wert aufweist.
** Ecken und Kurvendetektion - Rahmenbedingungen
+ Kanten:
  - Bildbereiche, in denen der Gradient in einer Richtung hoch und senkrecht dazu niedrig ist.
+ Eckpunkte:
  - Bildbereiche, in denen der Gradient in mehr als einer Richtung hoch ist.
+ Gewünschte Eigenschaften:
  - Unterscheidung von wichtigen und unwichtigen Eckpunkten
  - Zuverlässiges Auffinden von Eckpunkten unter Bildrauschen
  - Genaue Lokalisierung der Eckpunkte
  - Möglichst wenig Rechenaufwand
  - Unabhängig von der Orientierung der Ecken
+ Ideal: Empfindlichkeit per Parameter steuerbar
** Harris-Detektor: Strukturmatrix
+ Berechne wie bisher diskret genähert die partielle Bildableitung in horizontaler und vertikaler Richtung
+ Bilde daraus die so-genannte lokale Strukturmatrix
+ Dann Gewichtete Mittelung von M mit Gaußfilter H
+ Wenn (u,v) in einer strukturlosen Region des Bildes liegt (Intensitäts-"Gebirge" I ist flach, Plateau), dann sind sämtliche Ablei- tungen Ix=Iy=0, also ist M die Nullmatrix.
+ Wenn durch (u,v) eine Kante mit Kanten- vektor parallel zur x-Richtung verläuft, dann ist Ix2>0, also auch A>0, aber Iy=0, mit hin B=C=0. Wir haben also ein M in der Form
+ Wenn durch (u,v) eine Ecke verläuft (z.B. die Ecke eines Schachbrettmusters), dann messen wir an einigen Stellen in der Umgebung von (u,v) ein Ix2>0, an anderen Stellen ein Iy2>0.
  - Evtl. ist die Summe aber alle Terme IxIy im Fensterbereich Null (Schachbrett),
  - evtl. aber auch nicht (einseitige Ecke), wir haben also ein M in der Form
** !Eigenwert
+ Bekanntlich sind Eigenwert λ und Eigenvektor v einer Matrix M je diejenigen Elemente, für die die Eigenwertgleichung Mv = λv gilt.
+ Eigenvektoren sind also spezielle Richtungen im Raum, die die Abbildung M unverändert lässt.
+ Satz (ohne Beweis) :: jede reelle, symmetrische N*N-Matrix besitzt genau N reelle Eigenwerte mit N zueinander senkrechten Eigenvektoren.
** Interpretation der Eigenwerte
Eigenwerte codieren die Kantenstärke, Eigenvektoren die Kantenrichtung.
1. Fall: Innerhalb einer gleichförmigen (flachen) Bildregion ist M = 0 und deshalb sind auch die Eigenwerte λ1 = λ2 = 0.
2. Fall: Umgekehrt gilt auf einer perfekten Sprungkante λ1 > 0 und λ2 = 0, und zwar unabhängig von der Orientierung der Kante.
3. Fall: An Eckpunkten ist der Gradient in mehr als einer Richtung größer als 0: λ1 > 0; λ2 > 0.
** Hough Transformation
+ Kantendetektoren produzieren eine Vielzahl von irrelevanten Kanten, zusätzlich sind die wichtigen Kanten oft unzusammenhängend.
+ Mit der Hough-Transformation lassen sich beliebige, parametrisierbare Formen in Punktverteilungen lokalisieren (z.B.Geraden, Kreise, Ellipsen).
*** Parametrisierbare Formen - Geraden
+ Zweidimensionale Geradengleichung: y = kx + d
+ 2 Parameter: Steigung k und y-Achsenabschnitt d.
+ Für eine Gerade, die durch 2 Punkte p1 = (x1; y1) und p2 = (x2; y2) gilt y=kx1+d und y2=kx2+d
+ Ziel :: Auffinden der Geraden mit Para- metern k und d, auf denen möglichst viele Punkte liegen.
** Hough Transformation - Parameterraum
+ Die Hough-Transformation sucht im von k und d gebildeten zwei- dimensionalen Parameterraum alle Geraden, die durch einen gegebenen Punkt p0 = (x0; y0) laufen.
+ Sei Lj beliebige Gerade durch p0
+ Im Parameterraum ist die Menge aller Geraden durch p ebenfalls eine Gerade
+ Wenn sich n Geraden im Parameterraum an Position (k0; d0) schneiden, dann liegen auf der entsprechenden Geraden :y = k0x + d0 im Bildraum insgesamt n Bildpunkte.
+ Problem :: Vertikale Geraden haben Steigung k = ∞
+ Hessesche Normalform :: xcos0 + ysin0 = r

** Hough Transformation – Diskreter Parameterraum
+ Akkumulator-Array :: Diskrete Repräsentation des Parameterraumes.
+ Grundidee der Hough-Transformation :: Für jeden gefundenen Bildpunkt p0 werden die Zähler im Akkumulator-Array entlang der Geraden dj = x0kj + y0 um 1 erhöht.
** Hough Transformation – Pseudocode
** Hough Transformation: Details und Probleme
+ Problem :: Die Sinuskurven schneiden sich nicht genau an einem Punkt, sondern in einer Region. Die Lokalisierung der Maxima ist daher der schwierigste Teil der Hough-Transformation.

+ Ansatz A :: Schwellwerte. Alle Akkumulatorzellen unterhalb eines Schwellwertes werden verworfen. Die 9brigen werden mit einer morphologischen Closing-Operation bereinigt (ggf. später) und anschließend der Schwerpunkt der Regionen bestimmt.
+ Ansatz B :: Non-Maximum-Supression. Alle Nicht-Maxima werden verworfen, d.h. alle Zellen, deren Einträge nicht größer als die aller Nachbarn sind. Anschließend werden die größten Werte mit einer Schwellwertoperation gefunden.
+ Problem :: Gewicht einer Geraden bestimmt sich ausihrer Länge, aber weit vom Bildzentrum hat es oft zuwenig Platz f9r lange Geraden ) bestimmte Teile des Akkumulator-Arrays haben nicht die gleiche F9llwahrschein- lichkeit wie andere (Bias).
+ Ansatz :: Normierung mit der Anzahl nmax[θ; r] der überhaupt möglichen Geraden

* 07_Fourier-Analyse
** Fourier-Analyse - Motivation
+ Warum Transformationen?
+ Transformationen sollen gegebene Daten so umwandeln, dass
  - eine Bearbeitung weniger aufwendig ist oder überhaupt erst möglich wird
  - und eine eindeutige Wiederherstellung durch Rücktransformation möglich ist.
+ Fourier-Transformation ::
  - Übergang vom Ortsbereich (der uns vertrauten Darstellung) in den Frequenzbereich
  - Bildinformation bleibt identisch, Blickwinkel der Betrachtung ändert sich.
** Fourier-Transformation - Grundlagen
+ Zunächst Zerlegung des Bildes in Farbkanäle, dann sind nur noch Intensitäten der einzelnen Anteile zu untersuchen.
+ Intensitätswerte(bzw. Helligkeit) der einzelnen Pixel zeilenweise als Werte einer (kontinuierlichen) Funktion auffassen
+ Idee :: Repräsentiere eine Funktion als gewichtete Summe aus Sinus und Cosinus Termen.
*** Frage 1
 Welchen Vorteil bietet diese Frequenz-Zerlegung für die Bildverarbeitung bzw. Darstellung?
*** Antwort zu Frage 1
+ Die Koeffizienten der Consinus und Sinus Terme sind eine eindeutige Repräsentation des Bildes und geben an, aus welchen Frequenzanteilen sich das Bild zusammensetzt.
+ Während im Ortsraum ein Bild durch die Grauwerte seiner Pixel definiert wird, wird im Frequenz- raum ein Bild durch die in ihm vorkommenden periodischen Strukturen dargestellt.
+ Skalierung der Koeffizienten betont entsprechende Eigenschaften.

*** Frage 2:
Ist dies immer möglich, bzw. unter welchen
Bedingungen ist es möglich?

*** Antwort zu Frage 2: Fourier-Analyse
+ Fourier-Reihen :: Periodische Funktionen können als endliche Summe von sinus/Cosinus Funktionen dargestellt werden
  - Definitionsgebiet: Signal sit stetig auf Intervall, periodisch
  - Frequenzspektrum: Diskret
+ Fourier-Transformation :: Nicht-peridische Funktionen können als Integral von Sinus-/Cosinus Funktionen dargestellt werden
  – Definitionsgebiet: Signal ist stetig, aperiodisch.
  – Frequenzspektrum: stetig
+ Diskrete Fourier-Transformation(DFT,FFT) :: Endliche Folgen können als endliche Folge von Sinus-/Cosinus-Funktionen dargestellt werden
  - Definitionsgebiet: Signal ist diskret, endlich, periodisch fortgesetzt
  - Frequenzspektrum: Diskret, endlich
*** Formel der Fourier-Analyse
+ [ ] p 7-9
+ [ ] p 7-10
** Fourieranalyse - Komplexe Schreibweise
+ [ ] p 7-11
** Fourier-Koeffizienten
+ [ ] p 7-12
+ [ ] p 7-13
** Abtastung und diskrete Signale mathematisch
+ Wir nehmen an die Zeile eines Bildes ist eine Periode einer diskret abgetasteten kontinuierlichen periodischen Funktion
+ Ideale Abtastung von n Werten einer Funktion f innerhalb einer Periode mit gleichmäßigen Abständen
+ Nehme das Integral für die Koeffizienten nicht über das gesamte Signal sondern nur über eine Periodenlänge (= Länge der Bildzeile) und nehme also damit das Signal als periodisch an.
+ Durch das Sampling wird aus dem Integral auch rechnerisch eine Summe.
  - Das ist jetzt implementierbar: Denn sowohl das Integral für die Koeffizienten-Berechnung als auch die Rekonstruktion des Signals aus den Koeffizienten sind endliche Summen.
** Diskrete Fourier-Transformation

* 08_jpeg_kompression
** Bildspeicherung - Grundlagen
Zu beachtende Aspekt:
1. Kompression: verlustfrei, verlustbehaftet
2. Streaming-geeignet: bei langsamer Datenübertragung allmählicher Bildaufbau
3. Animation-geeignet: Nicht nur für Einzelbilder sondern auch Bildfolgen (Animationen)
4. Container-Format: unterstützt verschiedene Bild-Codierung
** Run-Length-Encoding
Idee: Jede Sequenz von identischen Symbolen durch deren Anzahl ersetzen. D.h. es werden nur die Stellen markiert, an denen sich das Symbol in der Nachricht ändert. Da die Längenangabe im Vergleich zur Länge der Sequenz nur logarithmisch wächst, spart man insbesondere bei langen Wiederholungssequenzen erheblich Speicherplatz. Umgekehrt ist die Einsparung umso geringer, je kürzer die Wiederholung sind. (Beispiel)
** Bildspeicherung - JPEG
*** Vorteile
+ Hohe Kompressionsrate
+ Wird von fast allen Rechnerplattformen unterstützt
+ Kann in fast jeder Bildbearbeitung verarbeitet werden.
*** Nachteile
+ Schlechte Kompression bei harten Kanten.
+ Nicht geeignet für Strichzeichnung mit wenigen Farben und harten Kanten.
+ Verlustbehaftete Kompression
+ Schärfe- und Farbverluste durch die Komprimierung
+ Block-Artefakte
** JPEG - Farbraumwechsel
*** RGB - Modell
Grundfarben Rot, Grün, Blau zur additiven Farbmischung. Im Rechner: z.B 8 Bit pro Grundfarbe, d.h. 0≤R,G,B≤255. Menge aller spezifizierbaren Farben wird im 3D-Raum durch einen Würfel repräsentiert ("Farbkörper"). Dieser deckt nicht den gesamten wahrnehmbaren Farbraum ab.
*** JPEG-Kompression - 1.Schritt
Transformation ins YCbCr Farbmodell, Tiefpassfilterung und Subsampling der Cb, Cr Kanäle.
+ Abtastverhältnis A:B:C :: In einem (2A)-Feld von Weten werden B Werte in der ersten zeile und C Werte in der zweiten Zeile abgetastet.
Grund: Menschliche Farbwahrnehmung geringer aufgelöst als Helligkeitsempfinden.
** JPEG - Blockbildung, DCT und Quantisierung
*** JPEG-Kompression - 2.Schritt: Blockbildung & DCT
Jeder Farbkanal wird in 8x8 Blöcke zerlegt. Diskrete Cosinus Transformation, wende die 2D-DCT auf die 8x8 Blöcke an. Die resultierenden Werte spiegeln den geometrischen Aufbau des Bildes wieder. Verlustbehaftet durch Rundungsfehler.
*** JPEG-Kompression - 3.Schritt: Quantisierung
Die Quantisierungsintervallbreite variiert je DCT-Koeffizient gemäß wahrnehmungsoptimierter Quantisierung, und zwa so, dass viele (unwichtige) Koeffizienten zu Null werden. Verlustbehafteter Kompressionsschritt.
** JPEG - verlustlose Kompression
*** JPEG-Kompression - 4. Schritt: Verlustlose Kompression
Umsortierung der Koeffizienten.
+ Kodierung der DC-Komponenten: Huffman Kodierung der Differenzen der DC-Komponenten
+ Kodierung der AC-Komponenten: RLE und anschließende huffman oder arithmetische Kodierung
Verlustlose Kompressionsschritte
** JPEG - Huffman Codierung
*** Grundidee
Codiere die auftretenden Symbole gemäß ihrer Häufigkeit. Häufige Symbole erhalten kurze Codes, seltene Symbole lange Codes. In Summe ergibt sich eine Ersparnis.

!Beispiel
*** Eigenschaften
+ Entwerder optimale Codierung gemäß der Häufigkeit auftretender Symbole berechnen, Algorithmisch Code Baum erstellen, präfixfreie Codierung
+ Oder mit empirisch ermittelten Tabellen arbeiten (bei JPEG gängig)
+ Unterschiedliche Tabellen für Luminanz und Chrominanz
+ Code-Tabellen und Quantisierungs-Tabellen werden mit in die Datei gespeichert

*** Bildspeicherung
Wie gut ist die Kompression? Abhäangig von dem zu codierenden Bild, Strichzeichnungen ungeeignet. Hohe Frequenzen werden gefiltert, d.h. Probleme wird es an scharfen Kanten geben.

Was sind die JPEG-Artefakte, die häufig zu sehen sind? Blockartefakt, deutlich sichtbare Blockbildung. Überschwingen, in Bereichen mit hohem Kontrast treten "Wellen" im Bild auf. Unschärfe, durch das Entfernen hoher Frequenzanteile.

* Zusammenfassung
CG2 Nachschreibeklausur WS 2016/17
** Wahrnehmung + Bildacquise (6 + 4)
*** a)Prinzip von Hell- und Dunkelfeldaufnahmen erläutern
**** Nennen von Eigenschaften mit Begründung, warum diese gelten
**** Jeweils Skizze mit Beschriftung
*** b)Kurz erläutern + Korrekturmöglichkeit:
**** chromatische + sphärische Aberration
**** Distorsion

** 10 Aufgaben für 10 Punkte (Ankreuz?)

** Kantendetektion (3 + 5)
*** Funktionsweise, Vor- und Nachteile der Detektion über 2te Ableitung
*** Canny-Edge-Kantendetektion und -Verfolgung erklären
**** Welche Parameter als Eingabe notwendig

** Eckendetektion (2 + 4 + 6)
*** 4 gewünschte Eigenschaften
*** ausführlich Funktionsweise der Strukturmatrix beim Harris-Detektor
*** Detalliert Arbeitsweise eines Harris-Detektors (inhaltlich vollständig aber ohne Formeln)
**** Welche Dinge in welcher Reihenfolge
**** Falls Subroutinen verwendet, diese auch erklären
** Fourier + Cosinus-Transformation (2 + 4 + 4)
*** Wie kann man einen Hochpassfilter mit DFT bauen?
*** Prinzipiell erklären wie DFT zu DCT erweitert werden kann
*** Vorteile von DCT gegenüber DFT

** JPEG (3 + 3 + 6)
*** Grundprinzip Run Length Encoding
*** Grundprinzip Huffman-Kodierung
*** Wesentliche Eigenschaften erklären
*** ausführlich wie Koeffizienten der DCT weiterverarbeitet werden und wie verlustfreie Kompression erreicht wird.
