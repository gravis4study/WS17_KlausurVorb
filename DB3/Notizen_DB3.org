* 02 Verwaltung des Hintergrundspeicher
** Speicherhierarchie
+ PrimÃ¤rspeicher - Register/Cache-Speicher
+ SekundÃ¤rspeicher - Langsamer SekundÃ¤rspeicher mit wahlfreiem Zugriff
+ TertiÃ¤rspeicher - Offline-TertiÃ¤rspeicher
** SekundÃ¤rspeicherorganisation
*** DatensÃ¤tze und Satztypen
+ Datensatz :: Folge von Datenfeldern mit je einem bestimmten Typ und einer bestimmenten(evtl.variablen) LÃ¤nge.
+ Satztypen:
  1. Feste SatzlÃ¤nge oder variable SatzlÃ¤nge
  2. DatensÃ¤tze mit variabler SatzlÃ¤nge
  3. "groÃŸe" SatzlaÌˆnge oder "kleine" SatzlaÌˆnge
     - groÃŸ: DatensaÌˆtze sind groÌˆÃŸer als ein Block
     - klein: DatensaÌˆtze passen in einen Block
*** Verwaltung von DatensaÌˆtzen in BloÌˆcken
+ Blockungsfaktor :: (durchschnittliche) Anzahl der DatensaÌˆtze pro Block
+ SpannsÃ¤tze :: Datensatz in mehreren BloÌˆcken
+ NichtspannsÃ¤tze :: jeder Datensatz in maximal einem Block
*** Adressierung von DatensaÌˆtzen
Indirekte Adressierung: "logische Adressierung", Adresse zeigt auf eine Zuordnungstablle, die die aktuelle physische Adresse enthÃ¤lt
*** Seitenbezogene Adressierung
Zeiger(Tupelidentifikator,TID) besteht aus einem Paar:(Seitennummer p, Position i im Zeigerfeld der Seite). Eintrag im Zeigerfeld:Position x des Satzes in der Seite an. Verschieben eines Datensatzes innerhalb der Seite: Nur x im Zeigerfeld verÃ¤ndern, alle Zeiger(p,i) auf den Satz bleiben unverÃ¤ndert.

Verschiebung eines Satzes in eine andere Seite:In der Seite P wird anstelle des Satzes der Zeiger <q,j> gespeichert, <q,j> gibt an, wo sich der Satz befindet
** Pufferverwaltung
*** Puffer UÌˆberblick
Ausgezeichneter Bereich des Hauptspeichers, in Pufferrahmen gegliedert. Jeder Pufferrahmen kann eine Seite der Platte aufnehmen
*** QualitaÌˆtsmaÃŸ fuÌˆr den Puffer
+ hit(Treffer)
+ miss(Fehlschlag)
+ hit ratio(Trefferrate)
*** Seitenersetzungsstrategien
**** Seitenersetzungsverfahren
+ Demand-Paging-Verfahren :: genau eine Seite im Puffer durch angeforderte Seite ersetzen.
+ Prepaging-Verfahren :: auch weitere Seiten in den Puffer lesen, die eventuell in der Zukunft benoÌˆtigt werden
**** Oft genutzte Strategien
+ FIFO :: Seite, die am laÌˆngsten im Puffer steht, wird ersetzt, Referenzen spielen keine Rolle
+ LFU :: (Least Frequently Used)Seite, die am seltensten referenziert wurde, wird ersetzt, Alter spielt keine Rolle
+ LRU :: (Least Recently Used)Seite, die am laÌˆngsten nicht referenziert wurde, wird ersetzt. Gesamtanzahl der Referenzen spielt keine Rolle.
+ GCLOCK :: Seite, die in juÌˆngster Zeit am wenigsten haÌˆufig referenziert wurde, wird ersetzt
*** Beispiel 1: LRU
Realisierung durch doppelt verkettete Liste aller Seiten mit Zeigern auf
+ Kopf (most recently used oder MRU - Ende) und
+ Ende (least recently used oder LRU - Ende)
Werden neue Objekte in den Pufferst gestellt, so werden sie am Kopf der Liste eingefuÌˆgt.
Werden Objekte, die im Puffer sind, erneut benutzt, so werden sie ausgekettet und am Kopf wieder eingefuÌˆgt.
*** Modifikationen von Seitenersetzungsstrategien
Standard â€“ Seitenersetzungsstrategien von BS brauchen Modifikationen fuÌˆr Einsatz in DBS
+ Fixieren von Seiten: Seite, die in naÌˆchster Zeit wieder benoÌˆtigt wird, kann im Puffer fixiert werden und ist damit von der VerdraÌˆngung ausgeschlossen
+ Freigeben von Seiten: Seite, die in naÌˆchster Zeit bestimmt nicht benoÌˆtigt wird, kann zur VerdraÌˆngung freigegeben werden
+ ZuruÌˆckschreiben einer Seite: DBS kann ausloÌˆsen, dass veraÌˆnderte Seiten in die Datendateien zuruÌˆckgeschrieben werden
** Logische Speicherorganisation in Orace
*** Tablespaces
+ unterteilen die Datenbank logisch in verschiedene Bereiche
+ kÃ¶nnen mehrere Dateien auf verschiedenen Plattenlaufwerken umfassen
*** Schema - Objekte
+ z.B Tabellen, indexe oder Stored Procedures
*** Segment
+ Speicher fÃ¼r Schema-Objekte, i.d.R. ein Schema-Obket pro Segment
+ Typen: Daten-Segmente, Index-Segmente, Undo-Segmente und temporÃ¤re Segmente
*** Extents
+ Werden dynamisch angefordert fÃ¼r die Speicherallokation fÃ¼r Segmente
+ Gesamter Speicher eines Extents wird gemeinsam reserviert und ist zusammenhÃ¤ngend
*** DatenbankblÃ¶cke
+ aus einem oder mehreren BS-BlÃ¶cken gebildet
+ D.h. hier wieder Kopplung an physische Speicherstruktur
+ Bausteine der Extents mit definierter, aber nicht fÃ¼r alle konstanter Anzahl
*** pctfree
legt fest, wie groÃŸ der Datenblockanteil sein soll, der nicht fÃ¼r EinfÃ¼geoperationen genutzt werden kann
* 03 Dateiorganisation und Zugriffspfade
** Begriffsdefinitionen
+ PrimaÌˆrschluÌˆssel :: ausgezeichnete identifizierende Attributmenge, wichtiger Kandidat fuÌˆr Zugriffsstruktur
+ SekundÃ¤rschlÃ¼ssel :: beliebige andere Attributmenge (die durch eine Zugriffsstruktur unterstuÌˆtzt werden soll)
+ Index :: Zugriffsstruktur, die den Zugriff uÌˆber Attributwerte unterstuÌˆtzt
+ PrimaÌˆrindex :: Zugriffsstruktur auf die DatensaÌˆtze, die die Dateiorganisationsform ausnutzen kann, im Normalfall uÌˆber PrimaÌˆrschluÌˆsselattributen definiert
+ SekundaÌˆrindex :: Jeder weitere Zugriffspfad
** Sequentielle Speicherung
+ Datei mit unsortierten DatensaÌˆtzen, wird auch Heap(Haufen) genannt
+ Datei mit sortierten DatensaÌˆtzen
** Hash-Basierte Speicherung
+ bucket = Speicherbereich, der aus einer oder mehreren Seiten besteht
*** Probleme des statischen Hashens
Mangelnde Dynamik
+ VergroÌˆÃŸerung des Bildbereichs erfordert komplettes Neu-Hashen
+ Wahl der Hash-Funktion entscheidend
** Cluster-Speicherung
UÌˆbliche Speicherverfahren:
+ Tupel uÌˆber Seiten verteilt ohne besondere BeruÌˆcksichtigung des logischen Zusammenhangs
Cluster â€“ Bildung, Ballung:
+ gemeinsame Speicherung von DatensaÌˆtzen, die in typischen Anfragen gemeinsam benoÌˆtigt werden
+ Gruppierung nach:
  - SchluÌˆsselattributen in Sortierreihenfolge: zur UnterstuÌˆtzung von Bereichsanfragen
  - oder DatensaÌˆtzen mit demselben Attributwert: zur UnterstuÌˆtzung von Verbundanfragen
Effizienzgewinn von der Art der Anfragen abhaÌˆngig
Indexierte Cluster
+ nutzen einen in Sortierreihenfolge aufgebauten Index (bspw. B+-Baum) uÌˆber den Cluster-SchluÌˆssel zum Zugriff auf die Cluster
Hash-Cluster
- bestimmen die Adresse eines Tupels mit Hilfe einer Hash-Funktion
- Hash-Funktion kann beim Anlegen des Clusters vom Benutzer definiert werden (sonst default-Funktion)
** Einstufige geordnete Indextypen
*** PrimÃ¤rindex
Geordnete Hauptdatai, Index nutzt diese Organisaionsform, Indexeintrag hat zwei Felder:SuchschlÃ¼ssel und Blockverweis. Je 1 Indexeintrag pro Datenblock der zugehÃ¶rigen Hauptdatei.
+ -> Nicht dichter Index
*** SekundÃ¶rindex
Dichter SekundÃ¤rindex nach nicht geordnetem Attribut. Doppelte SchlÃ¼sselwerte:
+ mehrfache EintrÃ¤ge
+ Verwendung von Buckets
*** Definition
PrimÃ¤rindex:
+ Zugriffsstruktur auf die DatensÃ¤tze, der die Dataiorganisationsform ausnutzen kann, im Normalfall Ã¼ber PrimÃ¤rschlÃ¼sselattributen definiert
+ ErgÃ¤nzung:Also z.B. auch ein Clusterindex
+ Alternative:Ein PrimÃ¤rindex ist ein Index, der die Position eines Datensatzes in der Datei bestimmt.
SekundÃ¤rindex:
+ Jeder weitere ZugriffsPfad

** Mehrstufige Indexe
Indexdatei plus Hauptdatei. DatensaÌˆtze in Indexdatei:
+ (PrimaÌˆrschluÌˆsselwert, Seitennummer)
zu jeder Seite der Hauptdatei genau ein Index-Datensatz in der Indexdatei
Wenn Hauptdatei groÃŸ wird, reicht ein Block fuÌˆr den Index nicht mehr aus.

Mehrstufiger Index: Bei sehr groÃŸen Dateien weitere Stufen erforderlich.

*** Probleme bei indexsequentiellen Dateien:
Stark wachsende Dateien:
+ Zahl der linear verketteten Indexseiten waÌˆchst
+ Automatische Anpassung der Stufenanzahl nicht vorgesehen
Stark schrumpfende Dateien:
+ nur zoÌˆgernde Verringerung der Index- und Hauptdatei-Seiten
Viele AÌˆnderungsoperationen:
+ Unausgeglichene Seiten in der Hauptdatei
+ FuÌˆhrt zu unnoÌˆtig hohem Speicherplatzbedarf und zu langen Zugriffszeiten

** Baum-basierte Indexe
*** B-BaÌˆume und Varianten
B-Baum:ausgeglichener oder balancierter Suchbaum
+ Daten im Baum werden sortiert nach einem Zugriffsattribute gespeichert
+ Alle Pfade von der Wurzel zu den BlÃ¤ttern des Baumes gleich lang
Datenbankbereich: Knoten der SuchbaÌˆume zugeschnitten auf Seitenstruktur des DBS
+ Mehrere Zugriffsattributwerte auf einer Seite
+ Mehrweg-BaÌˆume (mehr als zwei Nachfolger fuÌˆr einen Indexeintrag)
+ Alle SuchschluÌˆssel plus Verweise aus einem Knoten sollten auf eine Datenbankseite passen
*** Knotenstruktur im B-Baum
+ Ein Knoten entspricht einer Seite
+ Auslastung ausgewogen, Anzahl der Seitenzugriffe bei einer Suche durch BaumhoÌˆhe begrenzt
+ Balanciert: jeder Weg von der Wurzel bis zu einem Blatt gleich lang
+ Zu jedem Eintrag gibt es einen Verweis auf Knoten mit kleineren SchluÌˆsselwerten und auf Knoten mit groÌˆÃŸeren SchluÌˆsselwerten
+ Ein Eintrag besteht aus dem SchluÌˆssel und dem Datensatz, der zu diesen SchluÌˆssel gehoÌˆrt bzw. der entsprechenden TID
*** EinfuÌˆgen in B-Baum
+ Falls passende Seite n<2m Elemente, w einsorteiren
+ Falls passende Seite n=2m Elemente, neue Seite erzeugen(split)
  - ersten m Werte auf Originalseite
  - letzten m Werte auf neue Seite
  - mittleres Element auf entsprechende Indexseite nach oben

*** LÃ¶schen in B-Baum
Unterlaufbehandlung(bei weniger als m Elementen auf Seite)
+ Ausgleichen mit der benachbarten Seite (benachbarte Seite a Elemente
  mit n > m;transfer)
+ Oder : Zusammenlegen zweier Seiten zu einer (Nachbarseite n=m Elemente;fusion)

*** Verbesserung: B+-BaÌˆume
B+-BaÌˆume:
+ DatensaÌˆtze der Hauptdatei auf den Blattseiten
+ Innere Knoten enthalten Zugriffsattributwerte und Zeiger auf nachfolgende Knoten

*** Eigenschaften von B+-BaÌˆumen
+ Jeder Weg von der Wurzel zu einem Blatt hat die gleiche LaÌˆnge.
+ Jeder Knoten auÃŸer Wurzeln und BlaÌˆttern hat mindestens m und hoÌˆchstens 2m EintraÌˆge.
+ BlaÌˆtter haben mindestens a und hoÌˆchstens 2a EintraÌˆge.
+ Die Wurzel hat entweder maximal 2= EintraÌˆge, oder sie ist ein Blatt mit maximal 2a EintraÌˆgen
+ Jeder Knoten mit c âˆ’ 1 EintraÌˆgen, auÃŸer den BlaÌˆttern, hat c Kinder
Alle Operationen sind effizienter, da Baum breiter und damit weniger Ebenen!
** Weitere Zugriffsverfahren
*** Bitmap-Index
Beispiel: Attribut Type in Tabelle Movie nimmt ausschlieÃŸlich 5 verschiedene spezielle Werte an (C, G, S, T, V)
* 04 In Memory Database Systems
** Normale Idee
lade hauptsÃ¤chlich Datei in Hauptspeicher, um schneller lesen zu kÃ¶nnen
** Konzept
+ Data Management Operations -> Ã„nderung in Hauptspeicher wichtiger, in Persisitenze kommt spÃ¤ter
+ Data Query Operations -> spezifische Algorithms fÃ¼r optimierte Prozess, spezifische Lesenstruktur, spezifische Storage organization
+ Data Backup -> Persistenz hÃ¤ngt nicht von Hauptspeicher ab, nur fÃ¼r Backup
** !Most important aspects of IMDB
+ Dataiorganization basiert nicht auf Blcok
  + Zugriffszeit drastisch reduzieren
  + erfordet verschiedene Verarbeitungsalgorithmen
  + bevorzugt verschiedene Datenorganisation
+ intensive Operationen rechnen
  + erfordet verschiedene Verarbeitungsalgorithmen
  + benÃ¶tigen eine engere Integration mit Verarbeitungshardware
+ Persistenz Storage nur als "Backup"
+ Angenommen read-heavy Application
** Main memory data processing
+ Vermeidung die LÃ¼cke von Zugriffszeit bietet groÃŸen Vorteil
+ Core, L1 Cache, L2 Cache, L3 Cache, Main Memory, Disk
+ je schneller die Cache ist, destor kleiner ist die.
** Modification of data
+ zuerst verÃ¤ndert Datei in Hauptspeicher
+ Die VerÃ¤nderung an Redo log anhÃ¤ngen, Redo log ist nur fÃ¼r AnhÃ¤ngen
+ Die VerÃ¤nderung committen und dauerhaft
+ periodische Datei sind blockweise synchronisiert mit Festplatte.
** Important sapects of Oracle In Memory Storage
+ beschleunigen die analytsiche Abfrage transparent fÃ¼r Benutzer
+ fÃ¼r OLAP besonders hilfreich
+ In-memory Datei wird an SGA in Hauptspeicher speichert
+ 2 unterschieliche Teil:
  + "1MB Pool" fÃ¼r normale Datei
  + "64KB Pool"fÃ¼r Metadatai
+ Die GrÃ¶ÃŸe wurde dynamisch vergrÃ¶ÃŸert(reduziert nur nach Neustart)
+ Die Optionen kÃ¶nnen per Tablespace, Table und Column dynamisch verÃ¤ndert werden, und zwar, welche Teil soll in Hauptspeicher geladen werden.
+ Mehre Werte werden parallel in CPU-Register geladen
* 05 Recovery und Logging
** Fehlerklassen
+ Transaktionsfehler
  - lokaler Fehler einer Transaktion, z.B. Fehler im Anwendungsprogramm, Rollback-Kommando, Transaktionsabbruch durch das DBMS
+ Systemfehler
  - Fehler, die das gesamte System betreffen, z.B. DBMS-Fehler, Betriebssystemfehler, Hardware-Fehler. Alle im Hauptspeicher befindlichen Daten sind anschlieÃŸend zerstoÌˆrt.
+ Medienfehler
  - Fehler, die den Verlust der Daten im stabilen Speicher nach sich ziehen, z.B. Plattencrash, Controllerfehler, ZerstoÌˆrung der Festplatte durch aÌˆuÃŸere Gewalt
** Aufbau des Logfiles
+ Physisches Logging
+ Logisches Logging
+ Kombiniertes Logging
** Einbringstrategie
+ Direkt
  - eine verÃ¤nderte Seite wird direkt auf der Festplatte Ã¼berschrieben
+ Indirekt
  - Es gibt eine Seitentabelle, die zu jeder Seite die physische Adress auf der Festplatte beschreibt
  - GeÃ¤nderte Seiten werden auf neue Positionen geschrieben
  - Dann wird die neue Zuordnungstabelle geschrieben
  - Vorteil: Atomares einbrngen mehrerer Seiten
  - Nachteil: GrÃ¶ÃŸerer Aufwand, Clustereffekte werden zerstÃ¶rt
** AbhÃ¤ngigkeit zum Sperrverfahren
+ Das Log-Granulat muss kleiner oder gleich dem sperrgranulat sein
Warum?
+ Wenn groÌˆÃŸere Einheiten geloggt werden, werden auch groÌˆÃŸere Einheiten zuruÌˆckgesetzt oder wiederhergestellt.
+ Diese koÌˆnnten auch von anderen Transaktionen parallel veraÌˆndert worden sein, da sie ja nicht komplett gesperrt waren.
** AbhÃ¤ngigkeit zum Ausschreiben
+ steal/no steal :: steal: Eine Seite darf noch vor dem Commit ausgeschreiben werden ("dirty" bzw. "schmutzig")
+ force / no force :: force: Eine Seite muss vor dem Commit ausgeschrieben werden no force: Eine Seite darf auch nach dem Commit ausgeschrieben werden
** WAL-Prinzip und Commit-Regel
+ WAL (Write Ahead Log)-Prinzip
  - Vor dem Einbringen einer schmutzigen Seite muss die Undo-Information im Log ausgeschrieben sein
+ Commit-Regel
  - Vor dem Commit einer Transaktion muÌˆssen alle LogeintraÌˆge der Transaktion ausgeschrieben werden (fuÌˆr Redo)
** Commit-Verarbeitung
+ Standard-Commit
+ Gruppen-Commit
+ PrÃ¤-Commit
** Sicherungspunkt
Sicherungspunkt (checkpoint): Zusicherung, dass bis zu einem Zeitpunkt alle AÌˆnderungen in den stabilen Speicher geschrieben wurden.
** Unscharfe Sicherungspunkte
+ Es werden nur Statusinformationen geschrieben
+ Asynchron zum Checkpoint werden regelmaÌˆÃŸig Seiten ausgeschrieben
+ Zu jeder Seite im Puffer wird die Log-Adresse(LSN) der ersten Ã„nderung seit Einlesen der Seite gespeichert
+ Das Minimum dieser Werte ist die MinDirtyPageLSN
** Wiederherstellung
*** Analyse-Phase
+ Log wird vom letzten Checkpoint an gelesen
+ Menge der zum Checkpoint oder danach noch laufenden Transaktionen ermitteln
+ Gewinner-Transaktionen :: es wird ein Commit im Log gefunden
+ Verlierer-Transaktionen :: kein Commit oder ein Rollback im Log
+ Menge der Seiten, die zum Checkpoint-Zeitpunkt geaÌˆndert im Puffer lagen
+ Menge der Seiten, die seit dem Checkpoint noch geaÌˆndert wurden
*** Redo-Lauf
*** Undo-Lauf
** Idempotenz von Undo und Redo
LoÌˆsung: PageLSN
+ Dies ist immer die LSN der letzten AÌˆnderung auf der Seite
+ Kann als eine Versionsnummer verstanden werden
** Compensation Log Records (CLR)
+ Undo-Operationen werden als CLRs protokolliert
+ Die Seite erhaÌˆlt eine neue, hoÌˆhere PageLSN durch die Undo-Operation
+ Sowohl im Normalbetrieb als auch bei der Wiederherstellung
+ Diese AÌˆnderungen werden wie andere AÌˆnderungen protokolliert (WAL- Regel)
* 06 Anfrageoptimierung
** Grundprinzipien der Optimierung
1. Selektionen so frÃ¼h wie mÃ¶glich
2. Basisoperationen, die wie Selektion und Projektion
3. Redundante Operationen, Idempotenzen oder leere Zwischenrelationen entfernen
4. Zusammenfassen gleicher TeilausdrÃ¼cke
** Logische Optimierung
+ Komplexe SelektionspraÌˆdikate werden aufgeloÌˆst (Regel 4)
+ Mit Regel 11 werden kartesische Produkte mit anschlieÃŸender Selektion in Verbunde verwandelt
+ Mittels der Regeln 5, 6, 7, 8 werden Selektionen moÌˆglichst weit in Richtung der BlaÌˆtter verschoben
+ Gegebenenfalls muÌˆssen Selektionen gemaÌˆÃŸ Regel 4 vertauscht werden
+ Die Regeln 3, 5, 9 und 10 ermoÌˆglichen es, die Projektionen ebenfalls in Richtung BlaÌˆtter zu verschieben
+ Die Einzelschritte werden in dieser Reihenfolge so lange ausgefuÌˆhrt, bis keine Ersetzungen mehr moÌˆglich sind
** Interne Operationen
*** Selektion
+ Full Table Scan
+ Operationen zur Verarbeitung von TID-Listen: Materialisierung-Operator ğœ‡
*** Projektion
*** Verbund
+ DIRECT
+ SNGLOOP
+ MERGE
+ HASH
** Nested-Loop-Join
** Sort-Merge-Join
Voraussetzung: beide Relationen sind physisch nach dem Verbund-Attribut sortiert gespeichert!
Evtl. lohnt sich vorher eine externe Sortierung einer/beider Relationen, um dann dieses Verfahren nutzen zu koÌˆnnen
** Partition-Hash-Join
Join-Phase ist wie nested loops join auf den Partitionen
** Physische Optimierung
+ Beispiel Alternative 1: Nutzung Index auf Jahr
+ Beispiel Alternative 2: Nutzung mehrerer Indexe
*** Pipelining von Operationen
** Kostenbasierte Auswahl
EinflussgroÌˆÃŸen
+ TatsaÌˆchliche GroÌˆÃŸe der Datenbanktabellen
+ Existenz von PrimaÌˆr- und SekundaÌˆrindexen und ihre GroÌˆÃŸe
+ Clustering mehrerer Relationen
+ SelektivitaÌˆt eines Attributs, uÌˆber das ein Index aufgebaut wurde
*** Woher kommen die Informationen?
+ Statistiken uÌˆber die Datenbankinhalte
*** Histogramme fuÌˆr Attributwerte
** Optimizer Hints
Hint = Hinweis: der angegebene Zugriff muss nicht zwingend vom Optimierer verwendet werden
*** Syntax:
select /*+ hint */ <cols> from ...;

* 07 Relational Database Systems with Column Oriented Storage
** Motivation
+ row-wise tables: Eine einzele Spalte zu lesen ist sehr aufwendig
+ grÃ¶ÃŸe Rows haben viele NUll Wert
** Grundidee
+ Spaltenwerte kÃ¶nnen gut kompromiert werden
+ Zugriffszeiten reduzieren, indem nur erforderliche Spalten gelesen (geschrieben) werden
+ Spalten separat auf der Festplatte gespeichert
** Column storage can be beneficial
+ Viele Leseoperationen verwenden nur eine kleine Teilmenge von Spalten
+ Write Operationen sind hauptsÃ¤chlich Modifikation
+ SchemaÃ¤nderungen durch HinzufÃ¼gen / Entfernen von Spalten sind wahrscheinlich
+ fÃ¼r Read-Heavy System
** C-Store Projections
+ Projektion: Festplatte ist immer billiger, und es ist immer sinnvoller, die Performance durch redudante Datei zu verbesseren
+ Jede Spalte kann mehrmals gespeicert werden, in verschiedenen Reihnfolge
+ Gruppe von Spalten, die das gleiches Attribut speicheren, nennt Projektion
+ Index in Spaltenortierent Datenbank
+ Projektionen mit wenigen Spalten und anderen Sortierreihenfolgen werden genutzt, fÃ¼r eine bessere Leistung bei bestimmten Abfragen.
** Vectorization
How is a simple selection processed in a database system?
Example: SELECT AVG(revenue) FROM sales WHERE revenue<100

Vectorization kombiniert pipelining und full materialization:
+ nehmen erstmal 1000 Values, berechnen in Li Cache mit Full Materialization, und speichern diesen Durchschnitt als temporÃ¤res Ergebnis und Anzahl der Werte, die diesen Durchschnitt bilden
+ nehmen nÃ¤chste 1000 Values weiter (Pipline)
+ bis alle Values geladen werden, temporÃ¶res Ergebnis ist finales Ergebnis
*** Advantages of vectorization
Reduzierte Anzahl von Funktionsaufrufen im Vergleich zu reinem Pipelining, Bessere Cache-LokalitÃ¤t, Parallelisierung, mulitcore ausnutzen

** Data Compression
Daten in einer einzelnen Spalte sind homogen. Die hohe Leistung von Abfragen ist ein Hauptziel. HÃ¶here Komprimierung bedeutet weniger Speicherplatz.
*** Run-length encoding
Stores values with start index and number of repetitions for each run Beneficial for columns with long values (e.g. strings) and with many repetitions. Also efficient for sorted/ordered columns
*** Bit vector encoding
For each distinct value in a column a bit-vector is created with one bit for each row, Bit is 1 if that row has this value, 0 otherwise
*** Dictionary Encoding
dea: replace long values by shorter ones and manage this mapping in separate dictionarr Works well with few frequent (potentially long) values.
*** Frame of Reference
Idea: store only one value per column and represent all others by difference from this reference value
*** Read operations
Compression technique particularly efficient, if decoding is not required to answer queries, z.B SUM, COUNT, AVG
*** Management of NULL values
Tables with large number of columns often contain many NULL values By not storing NULL values much space can be saved
Three common options:
+ Position list
+ Position bit string
+ Position range
** Late materialization
Advanced implementations try to work with individual columns as long as possible in query execution,
Main advantages of late materialization:
+ Selection and aggregation tend to reduce number of rows to reconstruct
+ Operations on compressed data can be used in query plan (not possible if tuples are reconstructed earlier [and thus columns decompressed])
+ Amount of data to be moved between memory and CPU is reduced if only relevant columns are there for operations
+ More operations can be executed on fixed width columns (more efficient); after materialization if any column is variable length then so is the whole row
** Join Processing
Late materialization can also efficiently be applied to joins, Obvious idea: only fetch columns required in the join predicate first and only materialize rows in the join result
** Adaptive Indexing
Database system automatically creates the indexes it needs, Creation is adaptive, partial and continuous
* 09 MÃ¶gliche Fragen
1. IMDB çš„è€å¸ˆå››ä¸ªé—®é¢˜
2. Log çš„è®°å½•
3. ç®—å››ç§ Verbunde æ–¹æ³•çš„Kosten
4. Bæ ‘å’ŒB+æ ‘
